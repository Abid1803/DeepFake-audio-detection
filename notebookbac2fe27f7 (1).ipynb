{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8130934,"sourceType":"datasetVersion","datasetId":4555568}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"mohammedabdeldayem/the-fake-or-real-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T07:53:36.682190Z","iopub.execute_input":"2025-03-23T07:53:36.682516Z","iopub.status.idle":"2025-03-23T07:53:37.324278Z","shell.execute_reply.started":"2025-03-23T07:53:36.682486Z","shell.execute_reply":"2025-03-23T07:53:37.323306Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/the-fake-or-real-dataset\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, TimeDistributed, BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom tensorflow.keras.layers import Reshape\n\n# Define dataset path (automatically mounted by Kaggle)\nDATASET_PATH = \"/kaggle/input/the-fake-or-real-dataset/for-2sec/for-2seconds/training\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T07:53:40.572423Z","iopub.execute_input":"2025-03-23T07:53:40.572720Z","iopub.status.idle":"2025-03-23T07:53:42.195650Z","shell.execute_reply.started":"2025-03-23T07:53:40.572699Z","shell.execute_reply":"2025-03-23T07:53:42.194873Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def extract_features(file_path, sr=22050, n_mfcc=40):\n    y, sr = librosa.load(file_path, sr=sr)\n\n    # Compute Mel-Spectrogram\n    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n    mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n    \n    # Compute MFCCs\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n    \n    # Normalize and combine features\n    features = np.vstack([mel_spec[:40], mfcc])\n    \n    return features.T  # Transpose for shape (Time, Features)\n\n# Load dataset (Real and Fake samples)\ndef load_dataset(directory):\n    X, y = [], []\n    for label in [\"real\", \"fake\"]:\n        path = os.path.join(directory, label)\n        for file in os.listdir(path):\n            if file.endswith(\".wav\"):\n                features = extract_features(os.path.join(path, file))\n                X.append(features)\n                y.append(label)\n    \n    return np.array(X), np.array(y)\n\n# Load the dataset\nX, y = load_dataset(DATASET_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T07:53:45.068610Z","iopub.execute_input":"2025-03-23T07:53:45.069186Z","iopub.status.idle":"2025-03-23T08:00:07.700693Z","shell.execute_reply.started":"2025-03-23T07:53:45.069155Z","shell.execute_reply":"2025-03-23T08:00:07.699972Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"encoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y)\n\n# Normalize features\nscaler = StandardScaler()\nX = np.array([scaler.fit_transform(x) for x in X])\n\n# Reshape for CNN-LSTM (samples, time steps, features, 1)\nX = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\n# Convert labels to categorical format\ny_train = to_categorical(y_train, 2)\ny_test = to_categorical(y_test, 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T08:00:07.702055Z","iopub.execute_input":"2025-03-23T08:00:07.702782Z","iopub.status.idle":"2025-03-23T08:00:14.334259Z","shell.execute_reply.started":"2025-03-23T08:00:07.702750Z","shell.execute_reply":"2025-03-23T08:00:14.333539Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, TimeDistributed, Reshape, BatchNormalization, Input\n\n# Define Input Layer\ninput_layer = Input(shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3], 1))  \n\n# CNN Feature Extractor\nx = TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'))(input_layer)\nx = TimeDistributed(BatchNormalization())(x)\n\n\n\nx = TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same'))(x)\nx = TimeDistributed(BatchNormalization())(x)\n\n\n\nx = TimeDistributed(Flatten())(x)\n\n# Reshape before LSTM\nx = Reshape((X_train.shape[1], -1))(x)  #  Ensures correct shape\n\n# LSTM for Sequence Modeling\nx = LSTM(64, return_sequences=False)(x)\n\n# Fully Connected Layers\nx = Dense(64, activation=\"relu\")(x)\nx = Dropout(0.3)(x)\noutput_layer = Dense(2, activation=\"softmax\")(x)  # Output: Real or Fake\n\n# Define Model\nmodel = Model(inputs=input_layer, outputs=output_layer)\n\n# Compile Model\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\n# Train Model\nhistory = model.fit(X_train, y_train, epochs=30)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T08:00:14.335764Z","iopub.execute_input":"2025-03-23T08:00:14.336099Z","iopub.status.idle":"2025-03-23T08:43:34.776657Z","shell.execute_reply.started":"2025-03-23T08:00:14.336067Z","shell.execute_reply":"2025-03-23T08:43:34.775696Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 243ms/step - accuracy: 0.6976 - loss: 0.5611\nEpoch 2/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.8859 - loss: 0.2734\nEpoch 3/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.8978 - loss: 0.2462\nEpoch 4/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 243ms/step - accuracy: 0.9454 - loss: 0.1450\nEpoch 5/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 243ms/step - accuracy: 0.9458 - loss: 0.1398\nEpoch 6/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9525 - loss: 0.1305\nEpoch 7/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9613 - loss: 0.1036\nEpoch 8/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9731 - loss: 0.0696\nEpoch 9/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9725 - loss: 0.0800\nEpoch 10/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 243ms/step - accuracy: 0.9770 - loss: 0.0631\nEpoch 11/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 243ms/step - accuracy: 0.9806 - loss: 0.0542\nEpoch 12/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9832 - loss: 0.0449\nEpoch 13/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 243ms/step - accuracy: 0.9823 - loss: 0.0463\nEpoch 14/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9799 - loss: 0.0593\nEpoch 15/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 243ms/step - accuracy: 0.9782 - loss: 0.0574\nEpoch 16/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 243ms/step - accuracy: 0.9794 - loss: 0.0566\nEpoch 17/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9867 - loss: 0.0342\nEpoch 18/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9899 - loss: 0.0272\nEpoch 19/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9900 - loss: 0.0279\nEpoch 20/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9860 - loss: 0.0397\nEpoch 21/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9857 - loss: 0.0388\nEpoch 22/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9911 - loss: 0.0275\nEpoch 23/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9876 - loss: 0.0341\nEpoch 24/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9957 - loss: 0.0151\nEpoch 25/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9924 - loss: 0.0248\nEpoch 26/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9897 - loss: 0.0318\nEpoch 27/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9915 - loss: 0.0251\nEpoch 28/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9928 - loss: 0.0223\nEpoch 29/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9950 - loss: 0.0134\nEpoch 30/30\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 244ms/step - accuracy: 0.9957 - loss: 0.0111\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"acc=model.evaluate(X_test,y_test,verbose=0)[1]\nprint(acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:09:08.888021Z","iopub.execute_input":"2025-03-23T09:09:08.888391Z","iopub.status.idle":"2025-03-23T09:09:11.476050Z","shell.execute_reply.started":"2025-03-23T09:09:08.888332Z","shell.execute_reply":"2025-03-23T09:09:11.475108Z"}},"outputs":[{"name":"stdout","text":"0.9720630645751953\n","output_type":"stream"}],"execution_count":9}]}